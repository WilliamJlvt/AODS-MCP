"""
Exemple 1: Analyse de logs syst√®me

Ce cas d'usage d√©montre comment le Manager d√©l√®gue l'analyse de logs
√† un agent sp√©cialis√© qui identifie les erreurs et g√©n√®re un rapport.
"""
import asyncio
import os
import sys
from pathlib import Path

# Ajouter le r√©pertoire parent au path
sys.path.insert(0, str(Path(__file__).parent.parent))

from dotenv import load_dotenv
from openai import OpenAI
from agents.manager import ManagerAgent
from core.base import GraphManager
from core.orchestrator import Orchestrator

load_dotenv()


async def main():
    """Exemple d'analyse de logs avec d√©l√©gation."""
    
    # Configuration
    api_key = os.getenv("OPENAI_API_KEY")
    workspace_dir = "./workspace/examples/log_analysis"
    
    # Cr√©er le r√©pertoire de travail
    os.makedirs(workspace_dir, exist_ok=True)
    
    # Cr√©er des fichiers de log d'exemple
    log_content = """2024-02-05 10:15:23 INFO: Application d√©marr√©e
2024-02-05 10:15:24 INFO: Connexion √† la base de donn√©es r√©ussie
2024-02-05 10:16:45 WARNING: Cache presque plein (85%)
2024-02-05 10:17:12 ERROR: √âchec de connexion √† l'API externe: timeout
2024-02-05 10:17:13 INFO: Tentative de reconnexion...
2024-02-05 10:17:45 ERROR: √âchec de connexion √† l'API externe: timeout
2024-02-05 10:18:20 WARNING: Utilisation m√©moire √©lev√©e: 2.3GB
2024-02-05 10:19:05 INFO: Reconnexion r√©ussie
2024-02-05 10:20:15 ERROR: Erreur de validation: champ 'email' invalide
2024-02-05 10:21:30 INFO: Traitement de 150 requ√™tes
2024-02-05 10:22:45 WARNING: Latence √©lev√©e d√©tect√©e: 450ms
2024-02-05 10:23:10 ERROR: Erreur de validation: champ 'email' invalide
"""
    
    with open(f"{workspace_dir}/app.log", "w", encoding="utf-8") as f:
        f.write(log_content)
    
    # Initialiser le client
    import json
    if not api_key:
        print("‚ö†Ô∏è  Mode mock activ√© (pas de cl√© API)")
        class MockClient:
            class chat:
                class completions:
                    @staticmethod
                    def create(*args, **kwargs):
                        # Cr√©er le tool_call pour d√©l√©guer
                        print("[MOCK] G√©n√©ration d'un tool_call pour d√©l√©guer la t√¢che")
                        
                        class MockFunction:
                            def __init__(self):
                                self.name = "delegate_task"
                                self.arguments = json.dumps({
                                    "agent_name": "Analyste_Logs",
                                    "role": "Analyste de Logs Syst√®me",
                                    "instructions": "Analyse le fichier app.log, identifie toutes les erreurs et warnings, calcule des statistiques (nombre d'erreurs par type, fr√©quence) et g√©n√®re un rapport d√©taill√© dans rapport_analyse_logs.md",
                                    "system_prompt": "Tu es un expert en analyse de logs syst√®me. Tu identifies les patterns d'erreurs, calcule les statistiques et g√©n√®re des rapports clairs en Markdown."
                                })
                                print(f"[MOCK] Tool function cr√©√©e: {self.name}")
                        
                        class MockToolCall:
                            def __init__(self):
                                self.function = MockFunction()
                                self.id = "call_mock_123"
                                self.type = "function"
                                print(f"[MOCK] ToolCall cr√©√©: id={self.id}, type={self.type}")
                        
                        tool_call = MockToolCall()
                        
                        class MockMessage:
                            def __init__(self):
                                self.content = None
                                self.tool_calls = [tool_call]  # Utiliser l'instance cr√©√©e
                                self.role = "assistant"
                                print(f"[MOCK] Message cr√©√© avec {len(self.tool_calls)} tool_call(s)")
                        
                        message = MockMessage()
                        
                        class MockChoice:
                            def __init__(self):
                                self.message = message
                                self.finish_reason = "tool_calls"
                                print(f"[MOCK] Choice cr√©√© avec finish_reason: {self.finish_reason}")
                        
                        choice = MockChoice()
                        
                        class MockResponse:
                            def __init__(self):
                                self.choices = [choice]
                                print(f"[MOCK] Response cr√©√©e avec {len(self.choices)} choice(s)")
                        
                        response = MockResponse()
                        print("[MOCK] Mock response g√©n√©r√© avec succ√®s")
                        return response
        
        client = MockClient()
    else:
        client = OpenAI(api_key=api_key)
    
    # Initialiser le syst√®me
    print("=" * 70)
    print("üìä EXEMPLE 1: Analyse de Logs Syst√®me")
    print("=" * 70)
    
    graph_manager = GraphManager()
    orchestrator = Orchestrator(client, workspace_dir)
    orchestrator.graph_manager = graph_manager
    
    manager = ManagerAgent("Manager_Logs", client, graph_manager, orchestrator)
    
    print(f"\nüìÅ Workspace: {workspace_dir}")
    print(f"üìù Fichier de log cr√©√©: app.log\n")
    
    # Requ√™te
    query = """Analyse le fichier app.log dans le workspace. 
    Identifie toutes les erreurs et warnings, calcule des statistiques 
    (nombre d'erreurs par type, fr√©quence, etc.) et g√©n√®re un rapport 
    d√©taill√© dans un fichier rapport_analyse_logs.md"""
    
    print("üí¨ Requ√™te:")
    print(f"   {query}\n")
    print("-" * 70)
    print("üîÑ Traitement en cours...\n")
    
    try:
        result = await manager.process(query)
        
        print("\n" + "=" * 70)
        print("‚úÖ R√©sultat:")
        print("=" * 70)
        print(result)
        
        # Sauvegarder le graphe
        graph_path = orchestrator.save_graph(f"{workspace_dir}/graph.json")
        print(f"\nüìä Graphe sauvegard√©: {graph_path}")
        
        # V√©rifier si le rapport a √©t√© cr√©√©
        report_path = f"{workspace_dir}/rapport_analyse_logs.md"
        if os.path.exists(report_path):
            print(f"üìÑ Rapport g√©n√©r√©: {report_path}")
            with open(report_path, "r", encoding="utf-8") as f:
                print("\nüìã Contenu du rapport:")
                print("-" * 70)
                print(f.read()[:500] + "..." if len(f.read()) > 500 else f.read())
        
    except Exception as e:
        print(f"\n‚ùå Erreur: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
