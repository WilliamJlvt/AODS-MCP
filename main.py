import asyncio
import os
from dotenv import load_dotenv
from openai import OpenAI
from agents.manager import ManagerAgent
from core.base import GraphManager
from core.orchestrator import Orchestrator

# Charger les variables d'environnement
load_dotenv()


async def main():
    """Point d'entrÃ©e principal du systÃ¨me SYNERGOS-MCP."""
    
    # Configuration
    api_key = os.getenv("OPENAI_API_KEY")
    workspace_dir = os.getenv("WORKSPACE_DIR", "./workspace")
    
    if not api_key:
        print("âš ï¸  Attention: OPENAI_API_KEY non dÃ©finie. Utilisation d'un client mock.")
        print("ğŸ’¡ Pour utiliser le vrai LLM, crÃ©ez un fichier .env avec votre OPENAI_API_KEY\n")
        # Pour les tests sans API key, on peut utiliser un mock
        class MockClient:
            class chat:
                class completions:
                    @staticmethod
                    def create(*args, **kwargs):
                        # Retourner une rÃ©ponse mockÃ©e qui simule une dÃ©lÃ©gation
                        class MockToolCall:
                            class MockFunction:
                                name = "delegate_task"
                                arguments = '{"agent_name": "Worker_Mock", "role": "Test Worker", "instructions": "TÃ¢che de test mockÃ©e"}'
                            
                            function = MockFunction()
                        
                        class MockMessage:
                            content = None
                            tool_calls = [MockToolCall()]
                        
                        class MockChoice:
                            message = MockMessage()
                        
                        class MockResponse:
                            choices = [MockChoice()]
                        
                        return MockResponse()
        
        client = MockClient()
    else:
        client = OpenAI(api_key=api_key)
    
    # Initialisation du systÃ¨me
    print("=" * 60)
    print("ğŸš€ SYNERGOS-MCP - SystÃ¨me Multi-Agents")
    print("=" * 60)
    
    # CrÃ©er le gestionnaire de graphe
    graph_manager = GraphManager()
    
    # CrÃ©er l'orchestrateur
    orchestrator = Orchestrator(client, workspace_dir)
    orchestrator.graph_manager = graph_manager
    
    # Initialisation de l'agent Manager
    manager = ManagerAgent("Manager_Principal", client, graph_manager, orchestrator)
    
    print(f"\nğŸ“ Workspace: {workspace_dir}")
    print(f"ğŸ“Š Session ID: {graph_manager.session_id}\n")
    
    # Exemple de requÃªte
    print("-" * 60)
    print("ğŸ’¬ RequÃªte utilisateur:")
    mission = input("Entrez votre requÃªte (ou appuyez sur EntrÃ©e pour l'exemple): ").strip()
    
    if not mission:
        mission = "Analyse les fichiers du workspace et crÃ©e un rapport rÃ©capitulatif."
        print(f"Utilisation de l'exemple: {mission}")
    
    print("-" * 60)
    print("\nğŸ”„ Traitement en cours...\n")
    
    try:
        # ExÃ©cution
        result = await manager.process(mission)
        
        # Sauvegarder le graphe
        graph_path = orchestrator.save_graph()
        
        print("\n" + "=" * 60)
        print("âœ… RÃ©sultat final:")
        print("=" * 60)
        print(result)
        print("\n" + "=" * 60)
        print(f"ğŸ“Š Graphe sauvegardÃ©: {graph_path}")
        print(f"ğŸ“ Log de session: {workspace_dir}/session.log")
        print("=" * 60)
        
    except Exception as e:
        print(f"\nâŒ Erreur: {str(e)}")
        import traceback
        traceback.print_exc()
    
    finally:
        # Sauvegarder le graphe mÃªme en cas d'erreur
        try:
            orchestrator.save_graph()
        except:
            pass


if __name__ == "__main__":
    asyncio.run(main())
